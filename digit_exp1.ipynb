{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Importing required Packages######\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading the Mnist dataset######\n",
    "\n",
    "def load_mnist_dataset():\n",
    "    # load the MNIST dataset and stack the training data and testing\n",
    "    # data together (we'll create our own training and testing splits\n",
    "    # later in the project)\n",
    "    ((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()\n",
    "    data = np.vstack([trainData, testData])\n",
    "    labels = np.hstack([trainLabels, testLabels])\n",
    "    # return a 2-tuple of the MNIST data and labels\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape, trainLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data = np.empty(trainData.shape + (3,))\n",
    "template = np.zeros((28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_list = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(choice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Randomly assigning a (R or G or B)channel to each image######\n",
    "\n",
    "l = []\n",
    "for i in range(trainData.shape[0]):\n",
    "    template = np.zeros((28,28,3))\n",
    "    image = trainData[i,:,:]\n",
    "    n = np.random.choice(choice_list)\n",
    "    template[:,:,n] = image\n",
    "    l.append(template)\n",
    "    mod_data[i,:,:,:] = template\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc86f5b518>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mod_data[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mod_data[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(mod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(32,32, 3)))  \n",
    "top = base.output\n",
    "#top = MaxPooling2D(pool_size=(2, 2))(top)\n",
    "top = Flatten(name=\"flatten\")(top)\n",
    "top = Dense(64, activation=\"relu\")(top)\n",
    "top = Dropout(0.5)(top)\n",
    "top = Dense(32, activation=\"relu\")(top)\n",
    "top = Dense(10, activation=\"softmax\")(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = base.input, outputs=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('exp1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 14,749,930\n",
      "Trainable params: 14,749,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [cv2.resize(image, (32, 32)) for image in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc05c085c0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMY0lEQVR4nO3dX8hk9X3H8fenRknRhWissuhao0ghSLqKSCESLDTBeqMWLMnVFgJPLiroRSGSQmN7ZUu09ErYVslSWoNgUkVKVcRgemNd7aprN4l/MGZ1cQnbol6lid9ezFl43O4zz+zMmTNnnt/7BcPMnGd2znd/z/OZc87vnPn9UlVI2vl+Y9UFSBqGYZcaYdilRhh2qRGGXWqEYZca8alF/nGSm4C/A84C/qGq7t3m9Z7nk5asqnK65Zn3PHuSs4CfAl8GjgIvAF+rqv+a8m8Mu7RkW4V9kd3464E3quqtqvol8D3glgXeT9ISLRL2S4Cfb3p+tFsmaYQWOWY/3a7C/9tNT7IBbCywHkk9WCTsR4E9m55fCrx36ouqaj+wHzxml1Zpkd34F4CrknwuyTnAV4HH+ylLUt/m3rJX1a+S3AE8yeTU20NV9VpvlUnq1dyn3uZambvx0tIt49SbpDVi2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGLDT9k9q2DmOMnXZ8pka5ZZcaYdilRhh2qRGGXWqEYZcaYdilRix06i3J28CHwK+BX1XVdX0UpWH995SffWawKrRsfZxn//2q+kUP7yNpidyNlxqxaNgLeCrJi0k2+ihI0nIsuhv/xap6L8lFwNNJflxVz21+Qfch4AeBtGK9Tdmc5B7go6r6zpTXrMPl1M3ZyR10LV4b3/uUzUnOTbLr5GPgK8Dhed9P0nItsht/MfCDJCff55+r6t96qUq9a3WXap7/9/VTfvbCvIWMwNxhr6q3gN/tsRZJS+SpN6kRhl1qhGGXGmHYpUYYdqkRvV1UM9PKvKimF1+e8rOnBquiTetwkU7vF9VIWi+GXWqEYZcaYdilRhh2qRH2xq8hG3F17I2XNHqGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRHbhj3JQ0mOJzm8adkFSZ5O8np3f/5yy2xPTblJ85hly/5d4KZTlt0NPFNVVwHPdM8ljdi2Ye/mWz9xyuJbgAPd4wPArT3XJaln8x6zX1xVxwC6+4v6K0nSMiwyZfNMkmwAG8tej6Tp5t2yv59kN0B3f3yrF1bV/qq6rqqum3Ndknowb9gfB/Z1j/cBj/VTjqRl2XbAySQPAzcCFwLvA98G/gV4BLgMeAe4vapO7cQ73Xt55mgTG2NnGctglFsNOOnositkY+wsYw+7V9BJjTDsUiMMu9QIwy41wrBLjVj6FXSts8e9H9N6um3j2bhllxph2KVGGHapEYZdaoRhlxph2KVGeOrtDFyxxfI3B61iPMbyxQ/Nxi271AjDLjXCsEuNMOxSIwy71AiHpToDa138EoylN34sv5fRtIfDUkltM+xSIwy71AjDLjXCsEuNMOxSI7YNe5KHkhxPcnjTsnuSvJvkUHe7ebllalYZ8Kb1MsuW/bvATadZ/rdVtbe7/Wu/ZUnq27Zhr6rngG0nbZQ0boscs9+R5JVuN//83iqStBTzhv0B4EpgL3AMuG+rFybZSHIwycE51yWpBzNdG5/kcuCJqrr6TH52mteO5TLmuaxD8S12nI3l9zKWtu/12vgkuzc9vQ04vNVrJY3DtmPQJXkYuBG4MMlR4NvAjUn2MvlQfRv4xhJrlNQDv+J6Btah+LHsSg5pLL+XsbS9X3GVGmfYpUYYdqkRhl1qhGGXGuH0T6cYS8/uNGPp9dV6ccsuNcKwS40w7FIjDLvUCMMuNcKwS43w1JtGYx1Oe64zt+xSIwy71AjDLjXCsEuNMOxSI+yN16DscV8dt+xSIwy71AjDLjXCsEuNMOxSIwy71Ihtw55kT5JnkxxJ8lqSO7vlFyR5Osnr3b3TNvcoU27roLa4rbt1/r1sO/1TN4nj7qp6Kcku4EXgVuBPgBNVdW+Su4Hzq+qb27zX6H/fYylwHf54phlLO/ZtHX4vc0//VFXHquql7vGHwBHgEuAW4ED3sgNMPgAkjdQZHbN3c7FfAzwPXFxVx2DygQBc1Hdxkvoz8+WySc4DHgXuqqoPktl2aJJsABvzlSepLzNN2ZzkbOAJ4Mmqur9b9hPgxqo61h3X/7Cqfmeb9xn9odxYClyHY8NpxtKOfVuH38vcx+yZbMIfBI6cDHrncWBf93gf8NiiRUpanll6428AfgS8CnzcLf4Wk+P2R4DLgHeA26vqxDbvNfoP/LEUuBZbkFUXMIN1aMe+bbVln2k3vi+GfXbr8Ec6lraaZh3asW9z78ZL2hkMu9QIwy41wrBLjTDsUiMccHKk1qGneyxa7HGfh1t2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaMctcb3uSPJvkSJLXktzZLb8nybtJDnW3m5dfrnayzHnTbGaZ6203sLuqXkqyC3gRuBX4Y+CjqvrOzCtz+idNYXD7sdX0T9uOLltVx4Bj3eMPkxwBLum3PEnLdkbH7EkuB65hMoMrwB1JXknyUJLze65NUo9mDnuS84BHgbuq6gPgAeBKYC+TLf99W/y7jSQHkxzsoV5Jc5ppyuYkZwNPAE9W1f2n+fnlwBNVdfU27zP6Q+LRF7iDeczej7mnbE4S4EHgyOagdx13J90GHF60SEnLM0tv/A3Aj4BXgY+7xd8CvsZkF76At4FvdJ15095r9BvO0Re4JtxKr85WW/aZduP7YtjbYdhXZ+7deEk7g2GXGmHYpUYYdqkRhl1qxLbXxrdmWi/y97dYftsyClkD9rivF7fsUiMMu9QIwy41wrBLjTDsUiMMu9QIvwgj7TB+EUZqnGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRs8z19ukk/5Hk5SSvJfnLbvkFSZ5O8np375TN0ojNMtdbgHOr6qNuNtd/B+4E/gg4UVX3JrkbOL+qvrnNe/mtN2nJ5v7WW0181D09u7sVcAtwoFt+ALi1hzolLclMx+xJzkpyCDgOPF1VzwMXn5y1tbu/aHllSlrUTGGvql9X1V7gUuD6JFfPuoIkG0kOJjk4b5GSFndGvfFV9T/AD4GbgPeT7Abo7o9v8W/2V9V1VXXdgrVKWsAsvfG/leQz3ePfBP4A+DHwOLCve9k+4LFlFSlpcbP0xn+BSQfcWUw+HB6pqr9K8lngEeAy4B3g9qo6sc172RsvLdlWvfEOOCntMA44KTXOsEuNMOxSIwy71AjDLjXiUwOv7xfAz7rHF3bPV806Psk6Pmnd6vjtrX4w6Km3T6w4OTiGq+qswzpaqcPdeKkRhl1qxCrDvn+F697MOj7JOj5px9SxsmN2ScNyN15qxErCnuSmJD9J8kY3ft1KJHk7yatJDg05uEaSh5IcT3J407LBB/Dcoo57krzbtcmhJDcPUMeeJM8mOdINanpnt3zQNplSx6BtsrRBXqtq0BuTr8q+CVwBnAO8DHx+6Dq6Wt4GLlzBer8EXAsc3rTsb4C7u8d3A3+9ojruAf5s4PbYDVzbPd4F/BT4/NBtMqWOQdsECHBe9/hs4Hng9xZtj1Vs2a8H3qiqt6rql8D3mAxe2Yyqeg449bv/gw/guUUdg6uqY1X1Uvf4Q+AIcAkDt8mUOgZVE70P8rqKsF8C/HzT86OsoEE7BTyV5MUkGyuq4aQxDeB5R5JXut38QecDSHI5cA2TrdnK2uSUOmDgNlnGIK+rCPvpvli/qlMCX6yqa4E/BP40yZdWVMeYPABcCewFjgH3DbXiJOcBjwJ3VdUHQ613hjoGb5NaYJDXrawi7EeBPZueXwq8t4I6qKr3uvvjwA+YHGKsykwDeC5bVb3f/aF9DPw9A7VJNwHJo8A/VdX3u8WDt8np6lhVm3TrPuNBXreyirC/AFyV5HNJzgG+ymTwykElOTfJrpOPga8Ah6f/q6UaxQCeJ/+YOrcxQJt0sw49CBypqvs3/WjQNtmqjqHbZGmDvA7Vw3hKb+PNTHo63wT+fEU1XMHkTMDLwGtD1gE8zGR38H+Z7Ol8Hfgs8Azwend/wYrq+EfgVeCV7o9r9wB13MDkUO4V4FB3u3noNplSx6BtAnwB+M9ufYeBv+iWL9QeXkEnNcIr6KRGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxrxf31XZpnbref8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(255*data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99903494"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_lr = 1e-3\n",
    "epoch = 50\n",
    "bs= 64\n",
    "adm = Adam(lr=int_lr, decay=int_lr / epoch)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adm,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygen = ImageDataGenerator(\n",
    "\trotation_range=10,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=False,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-91-91edb1665743>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "  3/750 [..............................] - ETA: 20:14 - loss: 6.0402 - accuracy: 0.1406"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-91edb1665743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         epochs=epoch)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/dsc/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_model = model.fit_generator(mygen.flow(trainX, trainY, batch_size=bs),\n",
    "                        steps_per_epoch=len(trainX) // bs,\n",
    "                        validation_data=(testX, testY),\n",
    "                        validation_steps=len(testX) // bs,\n",
    "                        epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.empty(testData.shape + (3,))\n",
    "template = np.zeros((28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 230.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### Each pixel of test data is given a random color########\n",
    "\n",
    "t_l = []\n",
    "for i in tqdm(range(testData.shape[0])):\n",
    "    template = np.zeros((28,28,3))\n",
    "    image = testData[i,:,:]\n",
    "    for j in range(28):\n",
    "        for t in range(28):\n",
    "            n = np.random.choice(choice_list)\n",
    "            template[j,t,n] = image[j,t]\n",
    "            \n",
    "    t_l.append(template)\n",
    "    test_data[i,:,:,:] = template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_data[1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = testData[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = t_l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcbaf874978>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = [cv2.resize(image, (32, 32)) for image in t_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predIdxs = model.predict(t_data[1])\n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
